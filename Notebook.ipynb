{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba37039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.spatial import distance as dist\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f87d1f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\surta/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  8683d4f torch 1.9.0 CUDA:0 (GeForce GTX 1650, 4096.0MB)\n",
      "\n",
      "Fusing layers... \n",
      "C:\\Users\\surta\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "Model Summary: 224 layers, 7266973 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # or yolov5m, yolov5x, custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd2bada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint(ptA, ptB):\n",
    "    return ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc3aae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dist_ensemble(image, threshold, breadth, cord_thres, video):    \n",
    "    # Blue color in BGR \n",
    "    color = (255, 0, 0) \n",
    "\n",
    "    # Line thickness of 2 px \n",
    "    thickness = 2\n",
    "    conf = 0.3 #confidence threshold for 'person'\n",
    "    colors = ((0, 0, 255), (240, 0, 159), (0, 165, 255), (255, 255, 0),(255, 0, 255))\n",
    "    coord_file = cord_thres[labels == 0]\n",
    "    coord_file = coord_file[coord_file[:,-1] > conf]\n",
    "    coord_file = coord_file[coord_file[:, 0].argsort()]\n",
    "    for i in range(len(coord_file)):\n",
    "        (tl1, tr1, br1, bl1) = (int(coord_file[i][0]), int(coord_file[i][3])), (int(coord_file[i][2]), int(coord_file[i][3])), (int(coord_file[i][2]), int(coord_file[i][1])), (int(coord_file[i][0]), int(coord_file[i][1]))\n",
    "        for j in range(i+1,len(coord_file)):\n",
    "            image_copy = image\n",
    "            (tl2, tr2, br2, bl2) = (int(coord_file[j][0]), int(coord_file[j][3])), (int(coord_file[j][2]), int(coord_file[j][3])), (int(coord_file[j][2]), int(coord_file[j][1])), (int(coord_file[j][0]), int(coord_file[j][1]))\n",
    "            (xA, yA) = midpoint(tl1, tr1)\n",
    "            (xB, yB) = midpoint(tl2, tr2)\n",
    "            mid_pt = midpoint((xA, yA), (xB, yB))\n",
    "            D = dist.euclidean((xA, yA), (xB, yB))\n",
    "            D1 = dist.euclidean((xA, yA), mid_pt)\n",
    "            D2 = dist.euclidean(mid_pt, (xB, yB))\n",
    "            \n",
    "            if xB != xA:\n",
    "                slope = (yB - yA)/(xB - xA)\n",
    "                if abs(slope) > threshold:\n",
    "                    width = 5.7 # assumed height of the left most person (in ft.)\n",
    "                    corrected_D = width * D/(coord_file[i][3] - coord_file[i][1])\n",
    "                    cv2.putText(image_copy, \"{:.1f}ft.\".format(corrected_D), (int(xA), int(yA - 20)),cv2.FONT_HERSHEY_SIMPLEX, 0.55, color, 2)\n",
    "                else:\n",
    "                    corrected_D_width = breadth * D/(coord_file[i][2] - coord_file[i][0])\n",
    "                    cv2.putText(image_copy, \"{:.1f}ft.\".format(corrected_D_width), (int(xA), int(yA - 20)),cv2.FONT_HERSHEY_SIMPLEX, 0.55, color, 2)\n",
    "\n",
    "\n",
    "                start_point1 = tl1\n",
    "                end_point1 = br1 \n",
    "                start_point2 = tl2\n",
    "                end_point2 = br2 \n",
    "\n",
    "                # Using cv2.rectangle() method \n",
    "                # Draw a rectangle with blue line borders of thickness of 2 px \n",
    "                cv2.rectangle(image_copy, start_point1, end_point1, colors[0], thickness)\n",
    "                cv2.rectangle(image_copy, start_point2, end_point2, colors[1], thickness)\n",
    "                cv2.line(image, (int(xA), int(yA)), (int(xB), int(yB)),colors[2], thickness)\n",
    "                video.write(image_copy)\n",
    "                #cv2.imshow(\"Image\", image)\n",
    "                #cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a992080c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end of the video file...\n"
     ]
    }
   ],
   "source": [
    "video_path = 'video.mp4'\n",
    "video_output = 'density.mp4'\n",
    "\n",
    "video = cv2.VideoWriter(video_output, 0, 200, (1920,1080))\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_num = 0\n",
    "\n",
    "time_detection = []\n",
    "time_calculation = []\n",
    "\n",
    "while cap.isOpened():\n",
    "        frame_num += 1\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"end of the video file...\")\n",
    "            break\n",
    "        start1 = time.time()\n",
    "        image_bounding = cv2.resize(frame, (1920,1080))\n",
    "        #image_bounding = frame\n",
    "        results = model(image_bounding)\n",
    "        labels, cord_thres = results.xyxy[0][:, -1].cpu().numpy(), results.xyxy[0][:, :-1].cpu().numpy()\n",
    "        end1 = time.time()\n",
    "        time_detection.append((end1 - start1))\n",
    "        \n",
    "        image = cv2.resize(frame, (1920,1080))\n",
    "        start2 = time.time()\n",
    "        calc_dist_ensemble(image, 0.5, 1.8, cord_thres, video)\n",
    "        end2 = time.time()\n",
    "        time_calculation.append((end2 - start2))\n",
    "\n",
    "        #cv2.imshow(\"image with density detection\", frame)\n",
    "        #cv2.waitKey(1)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed65eb86",
   "metadata": {},
   "source": [
    "#### Mean time for YOLO to detect Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "574d413e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05586927623459787"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(time_detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c83d9e",
   "metadata": {},
   "source": [
    "#### Mean time to calculate distance between Humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9e08ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000559169054031372"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(time_calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e27b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [time_detection[i] + time_calculation[i]  for i in range(len(time_detection))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027088f6",
   "metadata": {},
   "source": [
    "#### Average time needed for each frame to be processed  by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87a02540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.056428445288629246"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
